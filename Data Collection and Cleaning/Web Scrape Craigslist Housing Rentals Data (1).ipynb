{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from time import time \n",
    "import requests\n",
    "from requests import get\n",
    "from warnings import warn \n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.core.display import clear_output\n",
    "from time import sleep\n",
    "import csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n",
      "Request: 121; Frequency: 2.411276227891977 request/s\n"
     ]
    }
   ],
   "source": [
    "# set errors to track number of erros\n",
    "errors = 0\n",
    "# track time during web scraping\n",
    "start_time = time()\n",
    "# track number of requests\n",
    "requests = 0\n",
    "# go through pages of craigslist rentals, divided 120 each page\n",
    "# and seemingly 2400 or less listings in total for the default Minneapolis\n",
    "# craigslist page\n",
    "listings_pages = [str(i) for i in range(0, 2400) if (i%120==0)]\n",
    "# iterate through listing pages which \n",
    "# contain numbers between 0-2400 divisble by 120\n",
    "for page in listings_pages:\n",
    "    # for page increment value by 120 each time to loop through \n",
    "    # groupings size 120 of craigslist rental ads and make request to url plus\n",
    "    # grouping indicated by number divisible by 120\n",
    "    driver = get('https://minneapolis.craigslist.org/search/apa?s=' + (page))\n",
    "    # create beautiful soup object\n",
    "    listing_object = BeautifulSoup(driver.content, 'html.parser')\n",
    "    # listing containers contains all 120 urls from the url requested with driver variable\n",
    "    listing_containers = listing_object.find_all('li', class_=\"result-row\")\n",
    "    # for each individual url contained in listing_containers\n",
    "    for item in listing_containers:\n",
    "        # increment requests for tracking purposes\n",
    "        requests += 1 \n",
    "        # track time\n",
    "        elapsed_time = time() - start_time\n",
    "        print ('Request: {}; Frequency: {} request/s'.format(requests, requests/elapsed_time))\n",
    "        # clear output for continous display of values\n",
    "        clear_output(wait = True)\n",
    "        # stop loop at 2500 requests\n",
    "        if requests > 2500:\n",
    "            warn('Number of requests was greater than 2280')\n",
    "            break\n",
    "        # get url of each link that appears on the page of 120 listings\n",
    "        try:\n",
    "            url = item.find('a', class_=\"result-title hdrlnk\")['href']\n",
    "        except AttributeError:\n",
    "            print ('cant append')\n",
    "        try:\n",
    "            # make request to url leading to single rental listing\n",
    "            link = get(url)\n",
    "            # create Beatufiul Soup object\n",
    "            listing_object = BeautifulSoup(link.content, 'html.parser')\n",
    "            # find everything in the \"section tag of each url\n",
    "            page_items = listing_object.find_all('section', class_=\"page-container\")\n",
    "            # scrape desired attributes by looping through \n",
    "            # \"section\" tag of each url\n",
    "            for container in page_items:\n",
    "                # these lists will become the columns for the data frame \n",
    "                # columns that they become are commented above each respective list\n",
    "                # the url list is not here but the variable is already set during each iteration as the \n",
    "                # 'price'\n",
    "                prices = []\n",
    "                # 'beds_baths'\n",
    "                bed_baths = []\n",
    "                # 'address'\n",
    "                addrs = []\n",
    "                # 'latitude'\n",
    "                lats = []\n",
    "                # 'longitude'\n",
    "                lons = []\n",
    "                # 'map accuracy'\n",
    "                accuracy = []\n",
    "                # 'datetime'\n",
    "                date_times = []\n",
    "                # 'title'\n",
    "                data_titles = []\n",
    "                # 'post id'\n",
    "                posting_ids = []\n",
    "                # 'square feet'\n",
    "                areas = []\n",
    "                # 'square feet 2'\n",
    "                title_price_and_attributes = []\n",
    "                # get price\n",
    "                try:\n",
    "                    price = container.h2.find(\"span\", class_=\"price\").text\n",
    "                    prices.append(price)\n",
    "                except AttributeError:\n",
    "                    prices.append(\"N/A\")\n",
    "                except TypeError:\n",
    "                    prices.append(\"N/A\")\n",
    "                # get latitutude\n",
    "                try:\n",
    "                    lat = container.find('div', class_=\"viewposting\")['data-latitude']\n",
    "                    lats.append(lat)\n",
    "                except TypeError:\n",
    "                    lats.append(\"N/A\")\n",
    "                except AttributeError:\n",
    "                    lats.append(\"N/A\")\n",
    "                # get longitude\n",
    "                try:\n",
    "                    lon = container.find('div', class_=\"viewposting\")['data-longitude']\n",
    "                    lons.append(lon)\n",
    "                except TypeError:\n",
    "                    lons.append(\"N/A\")\n",
    "                except AttributeError:\n",
    "                    lons.append(\"N/A\")\n",
    "                # get map data accuracy\n",
    "                try:\n",
    "                    data_accuracy = container.find('div', class_=\"viewposting\")['data-accuracy']\n",
    "                    accuracy.append(data_accuracy)\n",
    "                except TypeError:\n",
    "                    accuracy.append(\"N/A\")\n",
    "                except AttributeError:\n",
    "                    accuracy.append(\"N/A\")\n",
    "                # get datetime\n",
    "                try:\n",
    "                    date_time = container.find('time', class_=\"date timeago\")['datetime']\n",
    "                    date_times.append(date_time)\n",
    "                except TypeError:\n",
    "                    date_times.append(\"N/A\")\n",
    "                except AttributeError:\n",
    "                    date_times.append(\"N/A\")\n",
    "                # get bedrooms and baths\n",
    "                try:\n",
    "                    bed_bath = container.section.find_all(\"span\", class_=\"shared-line-bubble\")[0].text\n",
    "                    bed_baths.append(bed_bath)\n",
    "                except AttributeError:\n",
    "                    bed_baths.append(\"N/A\")\n",
    "                except TypeError:\n",
    "                    bed_baths.append(\"N/A\")\n",
    "                except IndexError:\n",
    "                    bed_baths.append(\"N/A\")\n",
    "                # get square feet\n",
    "                try: \n",
    "                    sqrft = container.section.find_all(\"span\", class_=\"shared-line-bubble\")[1].text\n",
    "                    areas.append(sqrft)\n",
    "                except AttributeError:\n",
    "                    areas.append(\"N/A\")\n",
    "                except TypeError:\n",
    "                    areas.append(\"N/A\")\n",
    "                except IndexError:\n",
    "                    areas.append(\"N/A\")\n",
    "                # get address \n",
    "                try:   \n",
    "                    addr = container.section.section.find(\"div\", class_=\"mapaddress\").text\n",
    "                    addrs.append(addr)\n",
    "                except AttributeError:\n",
    "                    addrs.append(\"N/A\")\n",
    "                # get title\n",
    "                try:\n",
    "                    data_title = container.h2.find(id=\"titletextonly\").text\n",
    "                    data_titles.append(data_title)\n",
    "                except AttributeError:\n",
    "                    data_titles.append(\"N/A\")\n",
    "                # get posting id\n",
    "                try:\n",
    "                    posting_id = container.find_all('p', class_=\"postinginfo\")[1].text\n",
    "                    posting_ids.append(posting_id)\n",
    "                except AttributeError:\n",
    "                    posting_ids.append(\"N/A\")\n",
    "                except IndexError:\n",
    "                    posting_ids.append(\"N/A\")\n",
    "                # this will be information in square feet 2\n",
    "                try:\n",
    "                    price_and_attributes = container.h2.find('span', class_=\"housing\").text\n",
    "                    title_price_and_attributes.append(price_and_attributes)\n",
    "                except AttributeError:\n",
    "                    title_price_and_attributes.append(\"N/A\")\n",
    "                # dataframe is updated in each loop \n",
    "                apartment_data = pd.DataFrame({'Url' : url, \n",
    "                                           'Price': prices,\n",
    "                                           'Address': addrs,\n",
    "                                           'Latitude': lats,\n",
    "                                           'Longitude': lons,\n",
    "                                           'Map Accuracy': accuracy,\n",
    "                                           'Date & Time Stamp': date_times,\n",
    "                                           'Bath/Bed': bed_baths, \n",
    "                                           'Areas' : areas,\n",
    "                                           'Listing Title': data_titles,\n",
    "                                           'ids' : posting_ids,\n",
    "                                           'Header': title_price_and_attributes\n",
    "                                           })\n",
    "                # leave dataframe open and call \"a\" for append option to append values iteratively\n",
    "                with open(\"test.csv\", \"a\", encoding='utf-8') as f:\n",
    "                    apartment_data.to_csv(f, header=False)\n",
    "        # keep track of requests that come back errors\n",
    "        except:\n",
    "            errors += 1\n",
    "            print(errors)\n",
    "            continue  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
