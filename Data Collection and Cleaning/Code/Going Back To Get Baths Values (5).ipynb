{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code was executed after cleaning all data to include baths attributes in analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas to work with dataframes\n",
    "import pandas as pd\n",
    "# import re to use regular expressions\n",
    "import re\n",
    "# import numpy\n",
    "import numpy as np\n",
    "# import glob to bring together multiple csv files\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search for csvs containing web-scraped data with the name scheme\n",
    "csvs = glob.glob(r'*Craigslist_ApartmentData_Minneapolis*.csv')\n",
    "# set dfs list to store each dataframe that gets read in\n",
    "dfs = []\n",
    "# iterate through csv files gathered in glob\n",
    "for file in csvs:\n",
    "    # read each csv as a dataframe with the same column names\n",
    "    df1 = pd.read_csv(file, names=['address', 'square feet', 'beds_baths', 'datetime', 'square feet 2', 'latitude', 'title', 'longitude', 'map accuracy', 'price', 'url', 'post id'])\n",
    "    # append dataframe to dfs list\n",
    "    dfs.append(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate dataframes in dfs together vertically\n",
    "df = pd.concat(dfs, axis=0)\n",
    "# check to see if address present, if it is, the boolean will be set to False\n",
    "# this seems counterintuitive\n",
    "df['address_check'] = [bool(re.match('nan', str(cell))) for cell in df['address']]\n",
    "# sort values by address_check column\n",
    "df = df.sort_values(['address_check'])\n",
    "# set an index of integers equal to the length of dataframe rows\n",
    "index_list = list(range(len(df.index)))\n",
    "# make index series a column in dataframe\n",
    "df['index'] = index_list\n",
    "# set index column as index of dataframe\n",
    "df = df.set_index(['index'])\n",
    "# set entire df type as string, as most operations will require data type to be string\n",
    "df = df.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop any post id values that are null\n",
    "postid_no_null = df.dropna(subset = ['post id'])\n",
    "# create dataframe where \"post id\" column is null\n",
    "null_id = df[df['post id'].isnull()]\n",
    "# drop duplicates in null_id dataframe using the \"title\" column\n",
    "null_id = null_id.drop_duplicates(subset=['title'], keep='first')\n",
    "# drop duplicates using \"post id\" column in the dataframe containing no null \"post id\" values\n",
    "postid_no_null = df.drop_duplicates(subset=['post id'], keep='first')\n",
    "# concatenate vertically null_id and postid_no_null dataframes\n",
    "df = pd.concat([null_id, postid_no_null])\n",
    "# drop latitude, longitude, map accuracy columns \n",
    "df = df.drop(columns=['latitude', 'longitude', 'map accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column to store baths values\n",
    "df['value_baths'] = [re.findall('\\d*\\.?\\d+Ba', str(cell)) for cell in df['beds_baths']]\n",
    "# create column of all patterns of baths values that exist in  beds_baths column\n",
    "df['baths_boolean'] = [bool(re.search('\\d*\\.?\\d+Ba', cell)) for cell in df['beds_baths']]\n",
    "# create baths column and clean so as to only get number \n",
    "df['baths'] = ''\n",
    "df.loc[df['baths_boolean'] == True, 'baths'] = df['value_baths'].apply(lambda x: str(x)[2:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice dataframe to just get the columns we need to make the join \n",
    "df_baths = df[['baths', 'url', 'datetime']]\n",
    "df_baths.to_csv(\"get_bath_values.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.read_csv(r\"C:\\Users\\murra667\\Documents\\Springboard\\Capstone _1\\Data_Collection\\Craigslist Data\\geocode_2\\Data Collection and Cleaning\\Data Sources\\cleaned_data_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_baths_merged = df_baths.merge(df_full, how = 'right', left_on = [\"url\", \"datetime\"], right_on = [\"url\", \"datetime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_baths_merged.to_csv(r\"C:\\Users\\murra667\\Documents\\Springboard\\Capstone _1\\Data_Collection\\Craigslist Data\\geocode_2\\Data Collection and Cleaning\\Data Sources\\final_df_with_baths.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform One Final Clean of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\murra667\\Documents\\Springboard\\Capstone _1\\Data_Collection\\Craigslist Data\\geocode_2\\Data Collection and Cleaning\\Data Sources\\final_df_with_baths.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the nulls to value Not Available\n",
    "df['baths'] = df['baths'].fillna(value = \"Not Available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'baths', 'url', 'datetime', 'index', 'address',\n",
       "       'beds boolean', 'beds_baths', 'county', 'county_full', 'geocode_lat',\n",
       "       'geocode_lon', 'post id', 'price', 'price boolean', 'square feet',\n",
       "       'square feet boolean', 'title', 'County', 'City', 'one to studio',\n",
       "       'bed assigned', 'index match', 'no match', 'outlier'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop county_full column\n",
    "df = df.drop(columns = ['index', 'Unnamed: 0', 'county_full', 'outlier', 'no match', 'index match', 'no match', 'County'])\n",
    "df = df.rename(columns = {'beds_baths' : 'beds'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r\"C:\\Users\\murra667\\Documents\\Springboard\\Capstone _1\\Data_Collection\\Craigslist Data\\geocode_2\\Data Collection and Cleaning\\Data Sources\\machine_learning_df.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
