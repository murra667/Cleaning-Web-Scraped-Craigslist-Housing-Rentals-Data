{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas to work with dataframes\n",
    "import pandas as pd\n",
    "# import re to use regular expressions\n",
    "import re\n",
    "# import numpy\n",
    "import numpy as np\n",
    "# import glob to bring together multiple csv files\n",
    "import glob\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import bokeh.plotting as bkp\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from collections import Counter\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search for csvs containing web-scraped data with the name scheme\n",
    "# ideally there will only be one geocoded file but for this project\n",
    "# there happene dto be several \n",
    "csvs = glob.glob(r'*geocode_craigslist*.csv')\n",
    "# set dfs list to store each dataframe that gets read in\n",
    "dfs = []\n",
    "# iterate through csv files gathered in glob\n",
    "for file in csvs:\n",
    "    # read each csv as a dataframe with the same column names\n",
    "    df1 = pd.read_csv(file)\n",
    "    # append dataframe to dfs list\n",
    "    dfs.append(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murra667\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# concatenate dataframes in dfs together vertically\n",
    "df = pd.concat(dfs, axis=0)\n",
    "# set an index of integers equal to the length of dataframe rows\n",
    "index_list = list(range(len(df.index)))\n",
    "# make index series a column in dataframe\n",
    "df['index'] = index_list\n",
    "# set index column as index of dataframe\n",
    "df = df.set_index(['index'])\n",
    "# set entire df type as string, as most operations will require data type to be string\n",
    "df = df.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get only rows from ramsey and hennepin county, and only rows where geocode_lat and geocode_lon are not \"none\n",
    "df_clean = df.loc[(df['geocode_lat'] != \"none\") & (df['geocode_lon'] != \"none\")]\n",
    "df_clean = df_clean.loc[(df_clean['county'] == \"ram\") | (df_clean['county'] == \"hnp\")]\n",
    "# remove \"geocode_lat\" and \"geocode_lon\" columns with \"error\" value\n",
    "df_clean = df_clean.loc[(df_clean['geocode_lat'] != \"error\") & (df_clean['geocode_lon'] != \"error\")]\n",
    "# drop columns that will not be necessary for analysis \n",
    "df_clean = df_clean.drop([\"county_state\", \"number_of_beds_1\", \"latitude\", \"longitude\", \"map accuracy\", \"square_feet_three\", \"square_feet_two\", \"square_feet_one\", \"Unnamed: 0\", \"address_check\", \"address_county\", \"address_lat\", \"address_lon\", \"check_superbowl\", \"county_lat\", \"county_lon\", \"square feet 2\", \"value_square_feet_two\", \"value_square_feet_three\", \"number_of_beds_2\", \"first_beds_boolean\", \"second_beds_boolean\", \"first_square_feet_boolean\", \"second_square_feet_boolean\", \"third_square_feet_boolean\"], axis = 1)    \n",
    "df_clean = df_clean.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import shapefile of hennepin county municipalities\n",
    "hennepin_county = \"Hennepin_County_Municipalities.shp\"\n",
    "# import shapefile of ramsey county municipalities\n",
    "ramsey_county = \"Cities.shp\"\n",
    "# set coordinate projection\n",
    "crs = {'init': 'epsg:4326'}\n",
    "# read hennepin_county cities shapefile as geopandas dataframe\n",
    "hennepin = gpd.read_file(hennepin_county)\n",
    "# set projection of dataframe to crs variable\n",
    "hennepin = hennepin.to_crs({'init': 'epsg:4326'})\n",
    "# read ramsey county cities shapefile as geopandas dataframe\n",
    "ramsey = gpd.read_file(ramsey_county)\n",
    "# set projection of dataframe to crs variable\n",
    "ramsey = ramsey.to_crs({'init': 'epsg:4326'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename column NAME_TXT to \"City\" so \n",
    "# ramsey and hennepin geodataframes have common in column\n",
    "# to perform join\n",
    "hennepin = hennepin.rename(columns = {\"NAME_TXT\" : \"City\"})\n",
    "# Set County column in both dataframes with respective counties\n",
    "hennepin['County'] = \"Hennepin\"\n",
    "ramsey['County'] = \"Ramsey\"\n",
    "# subset geodataframes to have the same types of columns\n",
    "hennepin = hennepin[['County', 'City', 'ShapeSTAre', 'ShapeSTLen', 'geometry']]\n",
    "ramsey = ramsey[['County', 'City', 'ShapeSTAre', 'ShapeSTLen', 'geometry']]\n",
    "# concatenate dataframes since both ramsey and hennepin county municipalities \n",
    "# will be included in analysis \n",
    "ramsey_hennepin = pd.concat([ramsey, hennepin], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set latitude and longitude columsn as float\n",
    "df_clean['geocode_lon'] = df_clean['geocode_lon'].astype(float)\n",
    "df_clean['geocode_lat'] = df_clean['geocode_lat'].astype(float)\n",
    "# convert latitude and longitude points from df_clean into geospatial data poitns\n",
    "geometry = [Point(xy) for xy in zip(df_clean['geocode_lon'], df_clean['geocode_lat'])]\n",
    "locations = gpd.GeoDataFrame(df_clean, crs=crs, geometry=geometry)\n",
    "locations = locations.to_crs({'init': 'epsg:4326'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a spatial join, such that points within ramsey and hennepin county\n",
    "# will be combined with columns containing municipal data \n",
    "counties_subset = gpd.sjoin(locations, ramsey_hennepin, how=\"right\", op='within')\n",
    "# subset columns of dataframe\n",
    "counties_subset = counties_subset.iloc[:, 1:18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set an index of integers equal to the length of dataframe rows\n",
    "index_list = list(range(len(counties_subset.index)))\n",
    "# make index series a column in dataframe\n",
    "counties_subset['index'] = index_list\n",
    "# set index column as index of dataframe\n",
    "counties_subset = counties_subset.set_index(['index'])\n",
    "counties_subset = pd.DataFrame(counties_subset)\n",
    "# drop nan values in geocode lat, geocode lon, \n",
    "# which will correspond to cities in Hennepin or Ramsey where\n",
    "# there are not craigslist ads\n",
    "counties_subset = counties_subset.dropna(subset = ['geocode_lat', 'geocode_lon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search for titles with \"studio\" in the title\n",
    "pattern = re.compile('studio', re.IGNORECASE)\n",
    "# subset beds that have a beds_baths value of 1 and see if they contain studio in the title\n",
    "counties_subset['one to studio'] = [bool(re.search(pattern, str(cell))) for cell in counties_subset['title']]\n",
    "# set one bedrooms that suggest that they are studio in the title as studios\n",
    "counties_subset.loc[counties_subset['one to studio'] == True, \"beds_baths\"] = \"studio\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert counties_subset beds_baths to string\n",
    "counties_subset['beds_baths'] = counties_subset['beds_baths'].astype(str)\n",
    "# create column in clean dataframe to verify if bed value is assigned in code to follow\n",
    "counties_subset['bed assigned'] = False\n",
    "# assign 'bed assigned' column to false for values that need to be inspected\n",
    "counties_subset.loc[(counties_subset['beds_baths'] == \"0\") | (counties_subset['beds_baths'] == \"0.0\") | (counties_subset['beds boolean'] == \"False\"), 'bed assigned'] = False\n",
    "# take a subset of listings without a beds value, with 0 as a bed value, or 0.0\n",
    "# as the titles of this subset will be insepcted to see if they can be assigned a beds value\n",
    "beds_none = counties_subset.loc[(counties_subset['beds_baths'] == \"0\") | (counties_subset['beds_baths'] == \"0.0\") | (counties_subset['beds boolean'] == \"False\")] \n",
    "# drop any listing that has beds, price and square feet values as null\n",
    "beds_none = beds_none.drop(beds_none[(beds_none['beds boolean'] == \"False\") & (beds_none['price boolean'] == \"False\") & (beds_none['square feet boolean'] == \"False\")].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of bed values and their index\n",
    "beds_none_list = beds_none.index.values.tolist()\n",
    "# create a list of titles\n",
    "titles_list = beds_none['title'].values.tolist()\n",
    "# zip the two lists so that the two values remain together\n",
    "beds_none_list = list(zip((beds_none_list), titles_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search for titles with \"studio\" in the title\n",
    "pattern = re.compile('studio', re.IGNORECASE)\n",
    "studios = [value for value in beds_none_list if bool(re.search(pattern, str(value[1])))]\n",
    "# search for titles that suggest they are 1 bedroom\n",
    "pattern = re.compile('one bedroom|1 bedroom|1 br|1br', re.IGNORECASE)\n",
    "ones = [value for value in beds_none_list if bool(re.search(pattern, str(value[1])))]\n",
    "# search for titles that suggest they are 2 bedroom\n",
    "pattern = re.compile('two bedroom|2 bedroom|2 br|2br', re.IGNORECASE)\n",
    "twos = [value for value in beds_none_list if bool(re.search(pattern, str(value[1])))]\n",
    "# search for titles that suggest they are 3 bedroom\n",
    "pattern = re.compile('three bedroom|3 bedroom|3 br|3br', re.IGNORECASE)\n",
    "three = [value for value in beds_none_list if bool(re.search(pattern, str(value[1])))]\n",
    "# search for titles that suggest they are 4 bedroom\n",
    "pattern = re.compile('four bedroom|4 bedroom|4 br|4br', re.IGNORECASE)\n",
    "# search for titles that suggest they are 4 bedroom\n",
    "four = [value for value in beds_none_list if bool(re.search(pattern, str(value[1])))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n",
      "92\n"
     ]
    }
   ],
   "source": [
    "print (len(studios))\n",
    "print (len(ones))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'beds_number_assigned' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-b00c9e23f96c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# use a Counter to determine which titles occur more than once in main list of\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# beds_number_assigned\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcount_beds_number\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeds_number_assigned\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mcount_beds_number\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mcount_beds_number\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcount_beds_number\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcount_beds_number\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcount_beds_number\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'beds_number_assigned' is not defined"
     ]
    }
   ],
   "source": [
    "# use a Counter to determine which titles occur more than once in main list of \n",
    "# beds_number_assigned\n",
    "count_beds_number = Counter(beds_number_assigned)\n",
    "count_beds_number = {k:count_beds_number[k] for k in count_beds_number if count_beds_number[k] > 1}\n",
    "print (count_beds_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see if there are any titles that were duplicated across the lists\n",
    "# to check integrity of regular expression pattern matching operations\n",
    "beds_number_assigned = ones + studios + twos + three + four\n",
    "# get the difference of the two lists, the beds not assigned\n",
    "beds_not_assigned = list(set(beds_none_list) - set(beds_number_assigned))\n",
    "# create list of lists of bedroom types that were or were not discovered\n",
    "# and in a certain order for iterative operations below\n",
    "bed_assignments_list = [studios, ones, twos, three, four]\n",
    "# loop through subset lists of beds values\n",
    "increment = 0\n",
    "for item in bed_assignments_list:\n",
    "    # filter nonetypes from list\n",
    "    indices = [x for x in item if x != None]\n",
    "    # get indices of bed values that were assigned using 'titles' column\n",
    "    # so they can be compared with indices of counties_subset\n",
    "    indices = [x for x, y in indices]\n",
    "     # compare indices assigned using 'titles' column\n",
    "    # to indices assigned \n",
    "    idx = counties_subset.index.isin(indices)\n",
    "    # add 'index match' column to counties_subset dataframe\n",
    "    counties_subset['index match'] = idx\n",
    "    # where 'index match' is true, set 'bed assigned' to yes, if false assign bed to \n",
    "    counties_subset.loc[(counties_subset['index match'] == True), 'bed assigned'] = True\n",
    "    # for studios group, assign value to studio\n",
    "    if increment == 0:\n",
    "        counties_subset.loc[counties_subset['index match'] == True, 'beds_baths'] = \"studio\"\n",
    "    # for other groups, assign to number of beds\n",
    "    else:\n",
    "        counties_subset.loc[counties_subset['index match'] == True, 'beds_baths'] = str(increment)\n",
    "    # add 1 to increment\n",
    "    increment += 1\n",
    "# get just indices from beds_not_assigned\n",
    "no_match = [x for x, y in beds_not_assigned]\n",
    "# get boolean comparing indices of dataframe with the no match column\n",
    "no_match_idx = counties_subset.index.isin(no_match)\n",
    "# assign boolean True false of no match column in dataframe\n",
    "counties_subset['no match'] = no_match_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data to pickle so as to examine unclassified beds and baths in inferential statistics \n",
    "unassigned = counties_subset.loc[counties_subset['no match'] == True]\n",
    "unassigned.to_pickle('unassigned_beds.pickle')\n",
    "# drop unassigned points from dataframe\n",
    "counties_subset = counties_subset.loc[counties_subset['no match'] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for all data, make sure that beds_baths column is consistent \n",
    "counties_subset.loc[(counties_subset['beds_baths'] == \"0.0\") | (counties_subset['beds_baths'] == \"0\"), \"beds_baths\"] = \"studio\"\n",
    "counties_subset.loc[(counties_subset['beds_baths'] == \"1.0\"), \"beds_baths\"] = \"1\"\n",
    "counties_subset.loc[(counties_subset['beds_baths'] == \"2.0\"), \"beds_baths\"] = \"2\"\n",
    "counties_subset.loc[(counties_subset['beds_baths'] == \"3.0\"), \"beds_baths\"] = \"3\"\n",
    "counties_subset.loc[(counties_subset['beds_baths'] == \"4.0\"), \"beds_baths\"] = \"4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all non-valid values from dataframe\n",
    "# in order to run EDA on beds_baths column\n",
    "df = counties_subset\n",
    "# drop bed_bath values that were not matched using the title column from analysis\n",
    "mask = df['no match'] == False\n",
    "df = df[mask]\n",
    "# subset data so as to only include studio - 4 bedrooms\n",
    "df = df.loc[(df['beds_baths'] == \"studio\") | (df['beds_baths'] == \"1\") | (df['beds_baths'] == \"2\") | (df['beds_baths'] == \"3\") | (df['beds_baths'] == \"4\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function that can deal with subset of values of \n",
    "# beds_baths columns and perform various operations such as standard deviation\n",
    "# and mean and store them in a dictionary\n",
    "def beds_statistics(df, column_name, column_boolean, beds_number = False):\n",
    "    # if beds_number parameter is empty, function runs through all beds values\n",
    "    if beds_number is False:\n",
    "        # variable to increment and set as dictionary key\n",
    "        count_beds = 0\n",
    "        # create dictionary to store values \n",
    "        values_dict = {}\n",
    "        # bed values studio -4 exist in dataset\n",
    "        for value in range(5):\n",
    "            # account for \"studio\" value in beds_baths which is a non-int\n",
    "            if value == 0:\n",
    "                count_beds = \"studio\"\n",
    "                subset = df.loc[(df[column_boolean] == \"True\") & (df[\"beds_baths\"] == \"studio\")]\n",
    "            else:\n",
    "            # subset data by beds value through each run in loop\n",
    "                subset = df.loc[(df[column_boolean] == \"True\") & (df[\"beds_baths\"] == str(count_beds))]\n",
    "            # make sure subset only includes non-null values of whatever attribute column is input into \n",
    "            # the function\n",
    "            subset = subset.loc[subset[column_boolean] == \"True\"]\n",
    "            # convert column of input attribute to numeric\n",
    "            subset[column_name] = pd.to_numeric(subset[column_name], errors='coerce')\n",
    "            # get mean of subset column\n",
    "            mean_value = (subset[column_name].mean())\n",
    "            mean_value = round(mean_value, 4)\n",
    "            # get standard deviation of subset column\n",
    "            std_value = np.std(subset[column_name])\n",
    "            std_value = round(std_value, 5)\n",
    "            #convert to array so as to use iqr function from statsmodel\n",
    "            new_array = subset[column_name].dropna()\n",
    "            new_array = new_array.as_matrix()\n",
    "            # call iqr function\n",
    "            iqr_value = stats.iqr(new_array, axis=None, rng=(25, 75), scale='raw', nan_policy='propagate', interpolation='linear', keepdims=False)\n",
    "            new_array = subset[column_name].dropna()\n",
    "            new_array = new_array.as_matrix()\n",
    "            # get 25th and 75th percentiles of subsetted column \n",
    "            q1, q3 = np.percentile(new_array, [25, 75])\n",
    "            # set lower boundary as 1.5 standard deviations below the 25th percentile as \n",
    "            # than that will produce negative values\n",
    "            lower = q1 - 1.5*(iqr_value)\n",
    "            # set upper boundary as 3 standard deviations above the 75th percentile so as to\n",
    "            # get rid of impossible rent values\n",
    "            upper = q3 + 3.0*(iqr_value)\n",
    "            # range of acceptable values will be those within the lower and upper bounds\n",
    "            outlier_range = (lower, upper)\n",
    "            # add percentiles to output dictionary\n",
    "            percentiles = (q1, q3)\n",
    "            # create dictionary key and nested dictionary as value\n",
    "            values_dict[count_beds] = {'iqr': iqr_value, 'mean': mean_value, 'std': std_value, 'outlier range': outlier_range, \"percentiles\": percentiles}\n",
    "            # account for \"studio\" value in beds_baths column\n",
    "            if count_beds == \"studio\":\n",
    "                count_beds = 0\n",
    "             # increment count of beds values so as to perform operations on next value from beds column\n",
    "            count_beds += 1\n",
    "        return values_dict\n",
    "    else:\n",
    "        # create dictionary to store values \n",
    "        values_dict = {}\n",
    "        # subset data by bed value entered in as beds_number parameter\n",
    "        mask = df['beds_baths'] == float(beds_number)\n",
    "        subset = df[mask]\n",
    "        # make sure subset only includes non-null values of whatever attribute column is input into \n",
    "        # the function\n",
    "        subset = subset.loc[subset[column_boolean] == \"True\"]\n",
    "        # convert column of input attribute to numeric\n",
    "        subset[column_name] = pd.to_numeric(subset[column_name], errors='coerce')\n",
    "        # get mean of subset column\n",
    "        mean_value = (subset[column_name].mean())\n",
    "        mean_value = round(mean_value, 2)\n",
    "        # get standard deviation of subset column\n",
    "        std_value = np.std(subset[column_name])\n",
    "        std_value = round(std_value, 5)\n",
    "        subset = subset.dropna()\n",
    "        #conver to array so as to use iqr function from statsmodel\n",
    "        new_array = subset[column_name].dropna()\n",
    "        # drop na from new array\n",
    "        #new_array.dropna()\n",
    "        # call iqr function\n",
    "        iqr_value = stats.iqr(new_array, axis=None, rng=(25, 75), scale='raw', nan_policy='propagate', interpolation='linear', keepdims=False)\n",
    "        # get 25th and 75th percentiles of subsetted column \n",
    "        q1, q3 = np.percentile(new_array, [25, 75])\n",
    "        # set lower boundary as 1.5 standard deviations below the 25th percentile as \n",
    "        # than that will produce negative values\n",
    "        lower = q1 - 1.5*(iqr_value)\n",
    "        # set upper boundary as 3 standard deviations above the 75th percentile so as to\n",
    "        # get rid of impossible rent values\n",
    "        upper = q3 + 3.0*(iqr_value)\n",
    "        # range of acceptable values will be those within the lower and upper bounds\n",
    "        outlier_range = (lower, upper)\n",
    "        # add percentiles to output dictionary\n",
    "        percentiles = (q1, q3)\n",
    "        # create dictionary key and nested dictionary as value\n",
    "        values_dict[count_beds] = {'iqr': iqr_value, 'mean': mean_value, 'std': std_value, 'outlier range': outlier_range, \"percentiles\": percentiles}\n",
    "        return values_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murra667\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:33: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "C:\\Users\\murra667\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:37: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "# create dictionaries of descriptive statistics values for price column \n",
    "# subsetted by bed value\n",
    "price_dict = beds_statistics(df, \"price\", \"price boolean\", beds_number = False)\n",
    "# create dictionaries of descriptive statistics values for square feet column \n",
    "# subsetted by bed value\n",
    "sqft_dict = beds_statistics(df, \"square feet\", \"square feet boolean\", beds_number = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to identify outliers in the data using previously defined outlier range\n",
    "def find_outliers(df, column_boolean, column_name, dictionary):\n",
    "    # subset only non-null values of whatever attribute column is input into the \n",
    "    # function and conver to numeric\n",
    "    df = df.loc[df[column_boolean] == \"True\"]\n",
    "    df[column_name] = pd.to_numeric(df[column_name], errors='coerce')\n",
    "    # Set column to identify outliers\n",
    "    df['outlier'] = False\n",
    "    # loop through bed values keys in dictionaries and determine whether values are outliers\n",
    "    for key in dictionary.items():\n",
    "        df.loc[(df[\"beds_baths\"] == str(key[0])) & (df[column_name] < (key[1]['outlier range'][0])), \"outlier\"] = True\n",
    "        df.loc[(df[\"beds_baths\"] == str(key[0])) & (df[column_name] > (key[1]['outlier range'][1])), \"outlier\"] = True\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murra667\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\murra667\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\murra667\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "# create dataframe that identifies outliers using function\n",
    "prices_outliers = find_outliers(df, \"price boolean\", \"price\", price_dict)\n",
    "# set an index of integers equal to the length of dataframe rows\n",
    "index_list = list(range(len(prices_outliers.index)))\n",
    "# make index series a column in dataframe\n",
    "prices_outliers['index'] = index_list\n",
    "# set index column as index of dataframe\n",
    "prices_outliers = prices_outliers.set_index(['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outliers grouped             outlier\n",
      "beds_baths         \n",
      "1              39.0\n",
      "2             228.0\n",
      "3               9.0\n",
      "4               1.0\n",
      "studio         19.0\n"
     ]
    }
   ],
   "source": [
    "# create groupby object of outliers to see where they tend to be distributed among beds groupings\n",
    "outliers_grouped = prices_outliers.groupby(['beds_baths']).agg({'outlier' : 'sum' })\n",
    "print (\"outliers grouped\", outliers_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outlier proportions beds_baths  outlier\n",
      "1           False      7498\n",
      "            True         39\n",
      "2           False      6741\n",
      "            True        228\n",
      "3           False      1457\n",
      "            True          9\n",
      "4           False       436\n",
      "            True          1\n",
      "studio      False       979\n",
      "            True         19\n",
      "Name: outlier, dtype: int64\n",
      "outlier percents beds_baths  outlier\n",
      "1           False      99.482553\n",
      "            True        0.517447\n",
      "2           False      96.728368\n",
      "            True        3.271632\n",
      "3           False      99.386085\n",
      "            True        0.613915\n",
      "4           False      99.771167\n",
      "            True        0.228833\n",
      "studio      False      98.096192\n",
      "            True        1.903808\n",
      "Name: outlier, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# create groupby objects to see where the proportion of outliers are distributed\n",
    "outliers_props = prices_outliers.groupby('beds_baths')[\"outlier\"].value_counts()\n",
    "outliers_percents = outliers_props.groupby(level=0).apply(lambda x: 100 * x / float(x.sum()))\n",
    "print (\"outlier proportions\", outliers_props)\n",
    "print (\"outlier percents\", outliers_percents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murra667\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:33: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "C:\\Users\\murra667\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:37: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "# subset dataframe to only contain non-outliers\n",
    "prices_no_outliers = prices_outliers.loc[prices_outliers['outlier'] == False]\n",
    "# get the statistics for the price column of dataframe without outliers\n",
    "prices_no_outliers_statistics = beds_statistics(prices_no_outliers, \"price\", \"price boolean\", beds_number = False)\n",
    "# do the same for square feet, but using prices_no_outliers dataframe\n",
    "sqft_no_outliers_statistics = beds_statistics(prices_no_outliers, \"square feet\", \"square feet boolean\", beds_number = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using prices_no_outliers_statistics dictionary\n",
    "# create dictionary of standard deviation and mean of \n",
    "# prices and square feet using the per beds grouping\n",
    "# for future use in data analysis with fair market rents\n",
    "price_mean_dict = {}\n",
    "price_std_dict = {}\n",
    "sqft_mean_dict = {}\n",
    "sqft_std_dict = {}\n",
    "for value in prices_no_outliers_statistics.items():\n",
    "    price_mean_dict[str(value[0])] = value[1]['mean']\n",
    "    price_std_dict[str(value[0])] = value[1]['std']\n",
    "for value in sqft_no_outliers_statistics.items():\n",
    "    sqft_mean_dict[str(value[0])] = value[1]['mean']\n",
    "    sqft_std_dict[str(value[0])] = value[1]['std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to save dictionaries for use in a later script\n",
    "def dict_to_pickle(dictionary, filename):\n",
    "    with open((str(filename) + \".pickle\"), 'wb') as handle:\n",
    "        pickle.dump(dictionary, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run function to save dictionaries for use in a later script\n",
    "dict_to_pickle(price_mean_dict, \"price_mean_dict\")\n",
    "dict_to_pickle(price_std_dict, \"price_std_dict\")\n",
    "dict_to_pickle(sqft_mean_dict, \"sqft_mean_dict\")\n",
    "dict_to_pickle(sqft_std_dict, \"sqft_std_dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "525.1914\n",
      "743.4594\n",
      "1077.3147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murra667\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1448.6534\n",
      "1675.3222\n"
     ]
    }
   ],
   "source": [
    "# fill null values with mean from prices_no_outliers_statistics dictionary\n",
    "# declare final dataframe\n",
    "final_df = prices_no_outliers\n",
    "# make sure that price and square feeet values are null where 'price boolean'\n",
    "# indicates False to be able to fill them with mean values\n",
    "#final_df.loc[final_df['price boolean'] == \"False\", \"price\"] = np.nan\n",
    "#final_df.loc[final_df['square feet boolean'] == \"False\", \"square feet\"] = np.nan\n",
    "# fill null values with the mean values of each bed type\n",
    "# from square feet mean and price mean dictionaries \n",
    "#final_df['price'] = final_df['price'].fillna(df['beds_baths'].apply(lambda x: price_mean_dict.get(x)))\n",
    "beds_types = [\"studio\", \"1\", \"2\", \"3\", \"4\"]\n",
    "for bed in beds_types:\n",
    "    print (sqft_mean_dict[bed])\n",
    "    final_df.loc[(final_df['square feet boolean'] == \"False\") & (final_df['beds_baths'] == str(bed)), 'square feet'] =  sqft_mean_dict[bed]\n",
    "    final_df.loc[(final_df['price boolean'] == \"False\") & (final_df['beds_baths'] == str(bed)), 'price'] =  price_mean_dict[bed]\n",
    "\n",
    "    # drop the index_left column to avoid future problems\n",
    "#final_df = final_df.drop(columns = ['index_left'])\n",
    "final_df.to_csv('cleaned_data_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "2. Zipcode tabulation areas of minnesota zip_code_tabulation_areas.shp\n",
    "\n",
    "3. Fair market rents data for Twin Cities 2018 https://www.huduser.gov/portal/datasets/fmr/fmrs/FY2018_code/2018summary.odn\n",
    "\n",
    "4. US Zipcodes Search Engine which uses census data\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
